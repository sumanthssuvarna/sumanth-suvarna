# -*- coding: utf-8 -*-
"""pyspark

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tQLfwk_a1LpG6hYdiDGltb6Ts1wr7_Lu
"""

!pip install pyspark py4j

from pyspark import SparkContext

a = SparkContext("local[*]", "word_count")

b = a.textFile("/content/sample_data/abc.txt.txt")

c = b.flatMap(lambda x: x.split(" "))

d= c.map(lambda x: x.lower())

e = d.countByValue()

print(e)